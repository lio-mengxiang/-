# 存储

* `[Point]` Sql
* `[Point]` NoSql
* `[Point]` 数据一致性

## 简介

科班的同学可以了解一下[数据库范式](http://www.cnblogs.com/CareySon/archive/2010/02/16/1668803.html), 在 ElemeFe 面试不会问, 但是其他地方可能会问 (比如阿里).


## Mysql夺命连环问

SQL (Structured Query Language) 是[关系式数据库管理系统](https://en.wikipedia.org/wiki/Relational_database)的标准语言, 关于关系型数据库这里主要带大家看一下 Mysql 的几个问题

## mysql 预算符连环问，请问以下输出什么，为什么呢
```SQL
SELECT 100 + '1' FROM DUAL; 
SELECT 100 + ’a‘ FROM DUAL; 
SELECT 100 + NULL FROM DUAL;
SELECT 1 = NULL FROM DUAL;
```
- 第一个输出101，原因是在SQL，+没有连接的作用，就表示运算，会讲字符串隐式转换为数值
- 第二个输出100，原因是会把'a'看做是0
- 第三个输出null, 因为null参与预算结果都是null
- 第四个输出null，因为只要有null参与判断，都返回null

那逻辑判断如何等于null呢？

使用 IS NULL

## char和varchar字符宽度的区别
请问char(M)和varchar(M)中，两个M分别指什么

- char和varchar最大的不同就是一个是固定长度,一个是可变长度.由于是可变长度,因此存储的是实际字符串再加上一个记录字符串长度的字节。如果分配给char或varchar列的值超过 列的最大长度,则对值进行裁剪.

- char(size) 最大255字符
- varchar(size) 最大65532字节，注意这里是字节，不同的编码，实际记录的字符是不一样的，而且这里不是65535，utf8编码最大21844字符，1-3个字节用于记录大小

## 字符集utf8和utf8mb4的区别，哪一个是mysql8的指定字符集
首先，mysql8官方默认字符集是utf8mb4

- utf8介绍
  - 最大字字符长度为3字节，如果遇到4字节的字符就会出现错误，也就是覆盖了unicode码的基本平面
  - 无法存表情和不常用汉字（unicode不在基本平面）
  - 消耗空间比utf8mb4少

- utf8mb4
 - 最大字符长度为4字节
 - 对于CHAR类型数据，存储会多消耗一些空间
 - 多了表情的支持

接着提问：对于排序，utf8mb4_unicode_ci与utf8mb4_general_ci如何选择

从准确性和性能两方面来看
- utf8mb4_unicode_ci是基于Unicode来排序和比较，能够在个语言之间精确排序
- utf8mb4_general_ci没有实现Unicode排序，在某些语言和特殊字符上，排序结果可能不如期望，但是在绝大数情况下，我们不需要这么精确的排序
从性能上来说
- utf8mb4_general_ci在比较和排序时更快

## SQL子查询题目

[参考这篇文章](https://juejin.cn/post/7083685848637505567)，这几道题拿两个面试面试者，会的话，尤其是相关子查询能做出来，说明后渲染sql基本还行。

## 字符集乱码问题

你能从mysql的
- 查询结果字符集(character_set_result)
- 客户端（character_set_client）
- 连接器（character_set_connection）
- server（character_set_server）
来说明乱码的原因。

解答：他们的关系如下图
```
客户端字符集 ------->    连接器字符集  ------> 
                         |   ↑               server字符集
查询结果字符集  <----------|    ↑------------
```
存数据：
- 客户端字符集如果跟连接器字符集不一样，会将客户端字符集转换为连接器字符集
- 连接器字符集如果跟server字符集不一致会转为server端字符集
取数据：
- server端字符集转为连接器字符集（如果不一样）
- 连接器字符集转为查询结果字符集（如果不一样）

所以在mysql5.7的默认字符集里，只有server和database是latin1，我们需要把server改为utf8就可以避免乱码了，但有时候这种修改没有用，举个例子。

1.如果客户端是 gbk 编码，而连接器是 latin1 编码，数据库是 utf8 编码，那么此时插入数据后查看是否乱码？

回答：是乱码的，因为在 gbk 编码转 latin1 编码时出现了丢失，这种丢失造成的乱码是不可修复的，所以数据库编码要大于连接器编码，连接器编码要大于客户端编码。

## mysql的逻辑结构
大致结构如下：
!['](https://pic1.zhimg.com/80/v2-044841d86673fdf7db91883ea5bc931c_1440w.jpg)

### 第一层：connectors

connectors，指的是不同语言与SQL的交互，MySQL首先是一个网络程序，在TCP定义了自己的应用层协议，所以要使用mysql，需要跟mysql server建立连接，按照协议交互。我们通常连接的客户端有很多，PHP、python、jdbc等等都有。

### 第二层：连接层

经过三次握手建立连接后，mysql对传输过来的账号密码做验证，获取权限，，此时mysql会创建一个连接池 + 长连接的方式管理连接

### 第三层: 服务层

主要是处理客户端请求的sql语句，如何处理呢？大致流程就是
- 查询缓存，如果有就用缓存，没有就进入到解析器截断，mysql8放弃了缓存这一层，为什么呢，因为绝大多数情况缓存命中率非常低，原因如下：
  - 查询请求要求在任何字符上都必须相同（例如:空格，注释，大小写变化，缓存失效）
  - 请求包含某些系统函数，用户自定义变量，如NOW，缓存失效
  - 本身缓存失效，比如使用INSERT，UPDATE，DELETE等语句
  - 只有对静态表而言缓存非常好
- 解析器：在解析器中对SQL语句进行语法分析，语义分析和ast抽象语法树
- 优化器：优化sql语句
- 执行器：没有真正去读写表，只是产生出了一个执行计划

### 第四层：引擎层

插件式的存储引擎，常见的有Inodb，myisam，它们真正负责了mysql中数据的存储和提取。


### 存储引擎

INNODB 还是 MYISAM的区别，对于实际工作，主要有三点使我们考量使用哪一种存储引擎的关键：
- 事务支持，INNODB支持，MYISAM不支持
- 缓存， MYISAM之缓存索引，不缓存真实数据，INNODB缓存索引，还缓存真实数据，对内存要求较高，而且内存大小对性能有决定性影响
- 行表锁，MYISAM支持表锁，不适合高并发操作。INNODB支持行锁，适合高并发场景。

### 索引

索引让数据查找很快，为啥不把数据的每一列都加上索引呢？

因为建立索引是有代价的：

- 空间上的代价

每建立一个索引都要为它建立一棵B+树，每一棵B+树的每一个节点都是一个数据页，一个页默认会 占用 16KB 的存储空间，一棵很大的B+树由许多数据页组成，那就是很大的一片存储空间。
- 时间上的代价

每次对表中的数据进行 增、删、改 操作时，都需要去修改各个B+树索引。而且我们讲过，B+树每 层节点都是按照索引列的值 从小到大的顺序排序 而组成了 双向链表 。不论是叶子节点中的记录，还 是内节点中的记录（也就是不论是用户记录还是目录项记录）都是按照索引列的值从小到大的顺序 而形成了一个单向链表。而增、删、改操作可能会对节点和记录的排序造成破坏，所以存储引擎需 要额外的时间进行一些 记录移位 ， 页面分裂 、 页面回收 等操作来维护好节点和记录的排序。如果 我们建了许多索引，每个索引对应的B+树都要进行相关的维护操作，会给性能拖后腿。

你可以接着询问b+tree的数据结构，从而1是如何证明上面的言论，而是更加深入的了解面试者的mysql数据结构上的理解。

如下如就是b+tree的数据结构
![1](https://img-blog.csdnimg.cn/img_convert/36ca56387f65d7351dd5acebf8326b89.png)


这种数据结构的优缺点如下：

#### 优点：

- 数据访问更快 ，因为聚簇索引将索引和数据保存在同一个B+树中，因此从聚簇索引中获取数据比非 聚簇索引更快
- 聚簇索引对于主键的 排序查找 和 范围查找 速度非常快
- 按照聚簇索引排列顺序，查询显示一定范围数据的时候，由于数据都是紧密相连，数据库不用从多 个数据块中提取数据，所以节省了大量的io操作 。
#### 缺点：

- 插入速度严重依赖于插入顺序 ，按照主键的顺序插入是最快的方式，否则将会出现页分裂，严重影 响性能。因此，对于InnoDB表，我们一般都会定义一个自增的ID列为主键
- 更新主键的代价很高 ，因为将会导致被更新的行移动。因此，对于InnoDB表，我们一般定义主键为 不可更新
- 二级索引访问需要两次索引查找 ，第一次找到主键值，第二次根据主键值找到行数据

### 索引

索引是用空间换时间的一种优化策略. 推荐阅读: [mysql索引类型](http://www.cnblogs.com/cq-home/p/3482101.html) 以及 [主键与唯一索引的区别](http://blog.mimvp.com/2015/03/the-difference-between-primary-key-and-unique-index/)


## 范式

### 为什么需要规范sql数据规范化？

数据设计不合理，会存在数据重复、更新插入异常等情况

### 三大范式

- 第一范式（1NF）：要求数据库的每一列都是不可分割的原子数据项，即原子性。
 

- 第二范式（2NF）：在满足第一范式的前提下，非码属性必须完全依赖于候选码，即表中的每一列都和主键相关，而不能至于主键的某一部分相关（主要针对联合主键而言），即每张表只描述一件事情。

- 第三范式（3NF）：在第二范式前提下，任何非主属性不依赖于其他非主属性（在2NF基础上，消除传递依赖）。即确保数据表中的每一列数据都和主键直接相关，而不能间接相关。


## Mongodb

> Monogdb 连接问题(超时/断开等)有可能是什么问题导致的?

* 网络问题
* 任务跑不完, 超过了 driver 的默认链接超时时间 (如 30s)
* Monogdb 宕机了
* 超过了连接空闲时间 (connection idle time) 被断开
* fd 不够用 (ulimit 设置)
* mongodb 最大连接数不够用 (可能是连接未复用导致)
* etc...


Mongodb我不熟，主要还是用mysql,这块待社区的同学补充

## Replication

> 备份数据库与 M/S, M/M 等部署方式的区别?

关于数据库基于各种模式的特点全部可以通过以下图片分清:

![storage](/assets/storage.jpeg)

图片出处：Google App Engine 的 co-founder Ryan Barrett 在 2009 年的 google i/o 上的演讲 [《Transaction Across DataCenter》](http://snarfed.org/transactions_across_datacenters_io.html)（视频： http://www.youtube.com/watch?v=srOgpXECblk） 

根据上图, 我们可以知道  Master/Slave 与 Master/Master 的关系.

<table>
  <tr><th>attr</th><th>Master/Slave</th><th>Master/Master</th></tr>
  <tr><td>一致性</td><td colspan="2">Eventually：当你写入一个新值后，有可能读不出来，但在某个时间窗口之后保证最终能读出来。比如：DNS，电子邮件、Amazon S3，Google搜索引擎这样的系统。</td></tr>
  <tr><td>事务</td><td align="center">完整</td><td align="center">本地</td></tr>
  <tr><td>延迟</td><td colspan="2" align="center">低延迟</td></tr>
  <tr><td>吞吐</td><td colspan="2" align="center">高吞吐</td></tr>
  <tr><td>数据丢失</td><td colspan="2" align="center">部分丢失</td></tr>
  <tr><td>熔断</td><td align="center">只读</td><td align="center">读/写</td></tr>
</table>

### 读写分离

读写分离是在 query 量大的情况下减轻单个 DB 节点压力, 优化数据库读/写速度的一种策略. 不论是 MySQL 还是 MongoDB 都可以进行读写分离.

 通常是 M/S 的情况, 使用 Master 专门写, 用 Slave 节点专门读. 使用读写分离时, 请确认读的请求对一致性要求不高, 因为从写库同步读库是有延迟的.


## 数据一致性

关于数据一致性推荐看陈皓的[分布式系统的事务处理](http://www.infoq.com/cn/articles/distributed-system-transaction-processing)

> 什么情况下数据会出现脏数据? 如何避免?

* 从 A 帐号中把余额读出来
* 对 A 帐号做减法操作
* 把结果写回 A 帐号中
* 从 B 帐号中把余额读出来
* 对 B 帐号做加法操作
* 把结果写回 B 帐号中

为了数据的一致性, 这6件事, 要么都成功做完, 要么都不成功, 而且这个操作的过程中, 对A、B帐号的其它访问必需锁死, 所谓锁死就是要排除其它的读写操作, 否则就会出现脏数据 ---- 即数据一致性的问题.

这个问题并不仅仅出现在数据库操作中, 普通的并发以及并行操作都可能导致出现脏数据. 避免出现脏数据通常是从架构上避免或者采用事务的思想处理.

### 矛盾

* 1）要想让数据有高可用性，就得写多份数据
* 2）写多份的问题会导致数据一致性的问题
* 3）数据一致性的问题又会引发性能问题

强一致性必然导致性能短板, 而弱一致性则有很好的性能但是存在数据安全(灾备数据丢失)/一致性(脏读/脏写等)的问题.

目前 Node.js 业内流行的主要是与 Mongodb 配合, 在数据一致性方面属于短板.

### 事务

事务并不仅仅是 sql 数据库中的一个功能, 也是分布式系统开发中的一个思想, 事务在分布式的问题中可以称为 "两阶段提交" (以下引用陈皓原文)

第一阶段：

* 协调者会问所有的参与者结点，是否可以执行提交操作。 
* 各个参与者开始事务执行的准备工作：如：为资源上锁，预留资源，写undo/redo log…… 
* 参与者响应协调者，如果事务的准备工作成功，则回应“可以提交”，否则回应“拒绝提交”。 

第二阶段：

* 如果所有的参与者都回应“可以提交”，那么，协调者向所有的参与者发送“正式提交”的命令。参与者完成正式提交，并释放所有资源，然后回应“完成”，协调者收集各结点的“完成”回应后结束这个Global Transaction。 
* 如果有一个参与者回应“拒绝提交”，那么，协调者向所有的参与者发送“回滚操作”，并释放所有资源，然后回应“回滚完成”，协调者收集各结点的“回滚”回应后，取消这个Global Transaction。 

异常:

* 如果第一阶段中，参与者没有收到询问请求，或是参与者的回应没有到达协调者。那么，需要协调者做超时处理，一旦超时，可以当作失败，也可以重试。
* 如果第二阶段中，正式提交发出后，如果有的参与者没有收到，或是参与者提交/回滚后的确认信息没有返回，一旦参与者的回应超时，要么重试，要么把那个参与者标记为问题结点剔除整个集群，这样可以保证服务结点都是数据一致性的。
* 第二阶段中，如果参与者收不到协调者的commit/fallback指令，参与者将处于“状态未知”阶段，参与者完全不知道要怎么办。





